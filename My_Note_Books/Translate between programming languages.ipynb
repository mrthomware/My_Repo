{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "To translate from one programming language to another we can use the comments to specify the source and target languages.\r\n",
    "Prompt\r\n",
    "\r\n",
    "##### Translate this function  from Python into Haskell\r\n",
    "### Python\r\n",
    "    \r\n",
    "    def predict_proba(X: Iterable[str]):\r\n",
    "        return np.array([predict_one_probas(tweet) for tweet in X])\r\n",
    "    \r\n",
    "### Haskell"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Settings\r\n",
    "Engine\r\n",
    "davinci-codex\r\n",
    "Max tokens\r\n",
    "54\r\n",
    "Temperature\r\n",
    "0\r\n",
    "Top p\r\n",
    "1.0\r\n",
    "Frequency penalty\r\n",
    "0.0\r\n",
    "Presence penalty\r\n",
    "0.0\r\n",
    "Stop sequence\r\n",
    "###"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Sample response\r\n",
    "\r\n",
    "predict_proba :: [String] -> [Probability] \r\n",
    "predict_proba = map predict_one_probas"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\r\n",
    "import openai\r\n",
    "\r\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\r\n",
    "\r\n",
    "response = openai.Completion.create(\r\n",
    "  engine=\"davinci-codex\",\r\n",
    "  prompt=\"##### Translate this function  from Python into Haskell\\n### Python\\n    \\n    def predict_proba(X: Iterable[str]):\\n        return np.array([predict_one_probas(tweet) for tweet in X])\\n    \\n### Haskell\",\r\n",
    "  temperature=0,\r\n",
    "  max_tokens=54,\r\n",
    "  top_p=1.0,\r\n",
    "  frequency_penalty=0.0,\r\n",
    "  presence_penalty=0.0,\r\n",
    "  stop=[\"###\"]\r\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}