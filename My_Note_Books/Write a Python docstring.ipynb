{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "An example of how to create a docstring for a given Python function. We specify the Python version, paste in the code, and then ask within a comment for a docstring, and give a characteristic beginning of a docstring (\"\"\").\r\n",
    "Prompt\r\n",
    "\r\n",
    "# Python 3.7\r\n",
    " \r\n",
    "def randomly_split_dataset(folder, filename, split_ratio=[0.8, 0.2]):\r\n",
    "    df = pd.read_json(folder + filename, lines=True)\r\n",
    "    train_name, test_name = \"train.jsonl\", \"test.jsonl\"\r\n",
    "    df_train, df_test = train_test_split(df, test_size=split_ratio[1], random_state=42)\r\n",
    "    df_train.to_json(folder + train_name, orient='records', lines=True)\r\n",
    "    df_test.to_json(folder + test_name, orient='records', lines=True)\r\n",
    "randomly_split_dataset('finetune_data/', 'dataset.jsonl')\r\n",
    "    \r\n",
    "# An elaborate, high quality docstring for the above function:\r\n",
    "\"\"\""
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Settings\r\n",
    "Engine\r\n",
    "davinci-codex\r\n",
    "Max tokens\r\n",
    "150\r\n",
    "Temperature\r\n",
    "0\r\n",
    "Top p\r\n",
    "1.0\r\n",
    "Frequency penalty\r\n",
    "0.0\r\n",
    "Presence penalty\r\n",
    "0.0\r\n",
    "Stop sequence\r\n",
    "#\"\"\""
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Sample response\r\n",
    "\r\n",
    "\"\"\" Randomly split a dataset into train and test. \r\n",
    "\r\n",
    "Parameters \r\n",
    "---------- \r\n",
    "folder : str\r\n",
    "    The folder where the dataset is located. \r\n",
    "filename : str \r\n",
    "    The name of the dataset file. \r\n",
    "split_ratio : list, optional \r\n",
    "    The ratio of train and test, by default [0.8, 0.2] \r\n",
    "\r\n",
    "Returns \r\n",
    "------- \r\n",
    "None \r\n",
    "    The function doesn't return anything, it just saves the train and test datasets in the given folder. \r\n",
    "\"\"\""
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\r\n",
    "import openai\r\n",
    "\r\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\r\n",
    "\r\n",
    "response = openai.Completion.create(\r\n",
    "  engine=\"davinci-codex\",\r\n",
    "  prompt=\"# Python 3.7\\n \\ndef randomly_split_dataset(folder, filename, split_ratio=[0.8, 0.2]):\\n    df = pd.read_json(folder + filename, lines=True)\\n    train_name, test_name = \\\"train.jsonl\\\", \\\"test.jsonl\\\"\\n    df_train, df_test = train_test_split(df, test_size=split_ratio[1], random_state=42)\\n    df_train.to_json(folder + train_name, orient='records', lines=True)\\n    df_test.to_json(folder + test_name, orient='records', lines=True)\\nrandomly_split_dataset('finetune_data/', 'dataset.jsonl')\\n    \\n# An elaborate, high quality docstring for the above function:\\n\\\"\\\"\\\"\",\r\n",
    "  temperature=0,\r\n",
    "  max_tokens=150,\r\n",
    "  top_p=1.0,\r\n",
    "  frequency_penalty=0.0,\r\n",
    "  presence_penalty=0.0,\r\n",
    "  stop=[\"#\", \"\\\"\\\"\\\"\"]\r\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}